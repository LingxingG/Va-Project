The purpose of this file is to: \
1. crawl the data from web \
2. combine all csv into one single DF
3. remove all speical characters ("-") to null values
4. Join area code to the main DF for every area
5. create subzone columns by mapping lat and lng columns with MLP shape into our data DF.
5. output one single csv file 

```{r echo = TRUE,eval=FALSE}
packages <-
  c('tidyverse',
  'data.table',
  'sf',
  'stringr',
  'lubridate',
  'dplyr')

for (p in packages) {
  if (!require(p, character.only = T)) {
    install.packages(p)
  }
    library(p, character.only = T)
}

```


```{r echo=TRUE, warning=FALSE}
months = list('01',
              '02',
              '03',
              '04',
              '05',
              '06',
              '07',
              '08',
              '09',
              '10',
              '11',
              '12')
areacode = read_csv("merged data\\AreaID.csv")
years <- list(1980:2019)

for (x in 1:nrow(areacode)){
  area = areacode[x,1]
  for (i in 1:length(years[[1]]-1)){
    year = years[[1]][i]
    for( month in months){
      downloadurl = paste(
          "http://www.weather.gov.sg/files/dailydata/DAILYDATA_",
          area,
          "_",
          sprintf("%s", year),
          month,
          ".csv",
          sep = ""
        )
      temp = paste(".\\raw data\\",
                   area,
                   "_",
                   sprintf("%s", year),
                   "_",
                   month,
                   ".csv",
                   sep = "")
      
      if (!file.exists(file.path(temp))){
          skip_to_next <- FALSE
          tryCatch(download.file(downloadurl,temp), error = function(e) { skip_to_next <<- TRUE})
          if(skip_to_next) { next }
      } 
    }
  }
}

```


```{r echo=TRUE, warning=FALSE}
file_location = "merged data\\dataset.csv"

if (file_test("-f", file_location )){
  DT = read_csv(file = file_location)
  print("File Loaded!")
}else{
  area_code_df = read_csv(file = "merged data\\area_geocode.csv")
  area_code_df <- area_code_df %>% mutate_at(vars(Lng), as.numeric)
  
  # load CRS
  mpsz <- st_read(dsn = "geospatial",
                  layer = "MP14_SUBZONE_WEB_PL")
  
  # convert the CRS to lat/lng
  mpsz <- st_transform(mpsz, 4326)
  
  # convert to a simple features object
  map2(area_code_df$Lng, area_code_df$Lat, ~ st_point(c(.x, .y))) %>%
    st_sfc(crs = 4326) %>%
    st_sf(area_code_df[, -(4:5)], .) -> tmp_sf
  
  # which subzone each one belongs in
  area_code_df <- bind_cols(area_code_df,
                            mpsz[as.numeric(st_within(tmp_sf, mpsz)),]) %>%
                            select(ID, Station, Region, Lat, Lng, SZ = SUBZONE_N) %>%
                            mutate(SZ = toupper(SZ))

  setwd("raw data\\")
  files <- list.files(pattern="*.csv")
  DT = do.call(rbind, lapply(files, fread))
  DT = rbindlist(lapply(files, fread))
  
  DT <- DT %>%
         mutate_all(funs(type.convert(as.character(replace(., .=="â€”", NA))))) %>%
         mutate(Month = month.abb[Month]) %>%
         left_join(area_code_df, by = c("Station")) %>%
         gather(Measurement, Value, 5:13)
  
  # Remove na rows
  DT =  DT[complete.cases(DT[ , 1]),]

  setwd("..\\")
  write_csv(DT,file_location,col_names = TRUE)
  print("File Created!")
}
```

